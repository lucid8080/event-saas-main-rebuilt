#!/usr/bin/env tsx

import { config } from 'dotenv';
import { join } from 'path';

// Load environment variables
config({ path: join(process.cwd(), '.env.local') });

async function testQwenInferenceProvider() {
  console.log('ğŸ¯ Testing Qwen via Hugging Face Inference Providers');
  console.log('==================================================\n');
  
  try {
    const { InferenceClient } = await import("@huggingface/inference");
    
    const token = process.env.NEXT_PUBLIC_HUGGING_FACE_API_TOKEN;
    if (!token) {
      console.log('âŒ No Hugging Face token found');
      return;
    }
    
    console.log(`ğŸ”‘ Using token: ${token.substring(0, 10)}...`);
    
    // Create InferenceClient
    const client = new InferenceClient(token);
    
    console.log('ğŸ§ª Testing Qwen-Image via Inference Providers...');
    
    try {
      console.log('ğŸ“¸ Generating image with Qwen-Image...');
      const startTime = Date.now();
      
      const image = await client.textToImage({
        provider: "auto", // Let HF choose the best provider
        model: "Qwen/Qwen-Image",
        inputs: "A beautiful landscape with mountains and a serene lake",
        parameters: { 
          num_inference_steps: 20,
          guidance_scale: 4.0
        },
      });
      
      const generationTime = Date.now() - startTime;
      
      console.log('ğŸ‰ SUCCESS! Qwen-Image worked via Inference Providers!');
      console.log(`â±ï¸ Generation Time: ${generationTime}ms`);
      console.log(`ğŸ“Š Image Type: ${image.type}`);
      console.log(`ğŸ“ Image Size: ${image.size} bytes`);
      
      // Convert blob to base64 for our system
      const arrayBuffer = await image.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);
      const base64 = buffer.toString('base64');
      const dataUrl = `data:${image.type};base64,${base64}`;
      
      console.log(`ğŸ–¼ï¸ Image Data: ${dataUrl.substring(0, 50)}...`);
      console.log(`ğŸ“ Base64 Length: ${base64.length} characters`);
      
      console.log('\nâœ¨ Benefits of Inference Providers:');
      console.log('âœ… Uses your Pro plan quotas properly');
      console.log('âœ… No Space API limitations');
      console.log('âœ… Direct access to Qwen-Image model');
      console.log('âœ… Better performance and reliability');
      console.log('âœ… THIS IS REAL QWEN-IMAGE!');
      
      return true;
      
    } catch (error) {
      console.error('âŒ Qwen Inference Provider failed:', error);
      
      if (error && typeof error === 'object') {
        console.log('\nğŸ“‹ Error Details:');
        if ('message' in error) console.log(`   Message: ${(error as any).message}`);
        if ('status' in error) console.log(`   Status: ${(error as any).status}`);
        if ('statusText' in error) console.log(`   Status Text: ${(error as any).statusText}`);
      }
      
      return false;
    }
    
  } catch (error) {
    console.error('âŒ Setup error:', error);
    return false;
  }
}

testQwenInferenceProvider().catch(console.error);
